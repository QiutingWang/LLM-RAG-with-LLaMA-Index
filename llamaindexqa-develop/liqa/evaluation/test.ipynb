{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "from typing import Optional\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index import (\n",
    "    ServiceContext,\n",
    ")\n",
    "\n",
    "from llama_index.embeddings import SimilarityMode, HuggingFaceEmbedding\n",
    "from liqa.load.format_pdf_reader import FormatPdfReader, ParaTitle\n",
    "from liqa.load.format_node_parser import FormatNodeParser\n",
    "from liqa.load import load_util\n",
    "from liqa.pipline import pipline_utils\n",
    "from liqa import utils\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2,3\"\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/nvme/share/share/yangyihe/embedding\"\n",
    "os.environ[\"LLAMA_INDEX_CACHE_DIR\"] = \"/nvme/share/share/yangyihe/embedding\"\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "# logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# 代理\n",
    "os.environ[\"http_proxy\"] = \"http://youhongming.p:you19980819*@10.1.8.50:33128/\"\n",
    "os.environ[\"https_proxy\"] = \"http://youhongming.p:you19980819*@10.1.8.50:33128/\"\n",
    "os.environ[\"HTTP_PROXY\"] = \"http://youhongming.p:you19980819*@10.1.8.50:33128/\"\n",
    "os.environ[\"HTTPS_PROXY\"] = \"http://youhongming.p:you19980819*@10.1.8.50:33128/\"\n",
    "\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.1,\n",
    "    api_key='sk-aJzbu0F3j7bstWlR3e4cA9Db59Ac4f669a9f471aFa66C458',\n",
    "    api_base='https://gf.nekoapi.com/v1'\n",
    ")\n",
    "# embed_model = \"local:BAAI/bge-large-zh\"\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-large-zh\",\n",
    "    cache_folder=\"/nvme/share/share/yangyihe/embedding\",\n",
    "    embed_batch_size=3,\n",
    ")\n",
    "service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model)\n",
    "vector_index = pipline_utils.create_vector_index(\n",
    "    input_dir=\"liqa/dataset/right\", service_context=service_context, use_storage = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from liqa.evaluation.eval_utils import EvalTool\n",
    "\n",
    "dataframe_path = \"openai_dataframe.csv\"\n",
    "if os.path.exists(dataframe_path):\n",
    "    dataframe = pd.read_csv(dataframe_path)\n",
    "else:\n",
    "    dataframe = EvalTool.read_source_table()\n",
    "    dataframe = EvalTool.construct_retriever_table(vector_index.as_retriever(), dataframe)\n",
    "    # dataframe = EvalTool.construct_response_table(vector_index.as_query_engine(), dataframe)\n",
    "    dataframe.to_csv(dataframe_path)\n",
    "    \n",
    "# dataframe[EvalTool.Key_Similarity] = dataframe.apply(\n",
    "#     lambda x : EvalTool.similarity_score(x[EvalTool.Key_References], x[EvalTool.Key_Responses]), axis=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file_percent = round(dataframe[EvalTool.Key_InFile].sum() / len(dataframe), 2)\n",
    "in_file_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_percent = round((dataframe[EvalTool.Key_Similarity] > 0.9).sum() / len(dataframe), 2)\n",
    "in_file_percent = round(dataframe[EvalTool.Key_InFile].sum() / len(dataframe), 2)\n",
    "print(f\"gpt3.5 In file:{in_file_percent} Similarity mean: {dataframe[EvalTool.Key_Similarity].mean()}, Similarity>0.9: {s_percent}\")\n",
    "\n",
    "\"\\n\".join([f\"##{score}, {node}\" for score, node in zip(dataframe[\"Score_1\"], dataframe[\"Node_1\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gpt3.5 Similarity mean: 0.8953468803239131, Similarity>0.9: 0.52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
